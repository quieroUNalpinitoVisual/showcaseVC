[{"id":0,"href":"/showcasevc/docs/shortcodes/Antialiasing/","title":"Antialiasing","section":"Shortcodes","content":" Antialiasing # Se desea trabajar en una implementacion del algoritmo de antialiasing y estudiar sus fenomenos.\n"},{"id":1,"href":"/showcasevc/docs/shortcodes/Antialiasing/AntialiasingLab/","title":"Antialiasing Lab","section":"Antialiasing","content":" Masking Lab # Seccion de pruebas de antialiasing.\nFlecha derecha: Generar nuevo triangulo\nFlecha izquierda: Pasar antialiasing\n"},{"id":2,"href":"/showcasevc/docs/shortcodes/Antialiasing/AntialiasingRes/","title":"Antialiasing Res","section":"Antialiasing","content":" Academic report # Introducci√≥n: # El Antialiasing (suavizado, antiescalonamiento o suavizado de bordes) son un conjunto de tecnicas diferentes las cuales quieren evitar el solapamiento de los bordes debida a representar una se√±al de alta resoluci√≥n en un monitor de baja resoluci√≥n.\nLiteratura: # M√©todos de AA: # Para lograr el efecto del antialiasing se realizan varios m√©todos con distintas aproximaciones:\nSuper sampling:\nBasicamente consiste en realizar un an√°logo de el muestreo de una se√±al analoga y aumentar el muestreo de la misma para obtener mejores datos. Multi-sampling:\nSe parece al algoritmo de super sampling pero difiere con el al momento de calculo de cada pixel, donde en SSAA se realizan varios calculos por pixel, en MSAA se realiza solo un calculo por pixel.\nEdge AA:\nEs un m√©todo propuesto por Deferred Shading en STALKER. En este se realiza primero un calculo de bordes de una imagen y a partir de esto se usa como m√°scara para saber en que lugares se debe realizar el algoritmo de AA. AA Morfol√≥gico:\nEn este m√©todo de dividen las areas de pixeles con colores similares en 3 tipos: Z, L y U. Tanto Z como U se pueden componer de tipos L. Ya con las areas de tipo L distinguidas usa modelado de triangulos para realizar el calculo del antialiasing.\nDeep Learning Super Sample:\nEste algortimo desarrollado por Nvidia hace uso de los subprocesadores de tipo Tensor en las nuevas graficas de la compa√±ia para implementar Super Sampling mediante una IA. AMD FidelityFX Contrast Adaptive Sharpening:\nEste algoritmo de antialiasing temporal es desarrollado por AMD technologies y posee una base de codigo abierto para su uso. Ademas de proveer antialiasing, tambien posee funciones de escalamiento y sharpening.\nImplementaci√≥n # En el apartado de AntialiasingLab se puede encontrar un ejemplo de implementacion de SSAA basado en la facilidad que tenemos de obtener la referencia real de la figura que estamos modelando, en este caso es un tri√°ngulo aleatorio que se dibuja en una cuadrilla.\nEn la funcion que describimos a continuacion en el expandible encontramos los loops que recorren la simulacion de una imagen de mas alta resoluci√≥n (64 a 1) y van hayando donde el triangulo discreto (en este caso dibujado con la funcion de Quadrille.js) y el triangulo real que se dibuja con la primitiva triangle() de p5. Damos un peso relativo de acuerdo a cuantos pixeles de la imagen de alta resolucion poseen el triangulo y lo dibujamos luego en la cuadrilla de menor resoluci√≥n\nExpand ‚Üï p5 code # function supersamp(){ let total = 64; for (let i = 0; i \u0026lt; QUADDIM ; i ++) { for (let j = 0; j \u0026lt; QUADDIM ; j ++) { let count = 0; let si = LENGTH * i +1; let sj = LENGTH * j + 1; for (; si \u0026lt; LENGTH * i + LENGTH - 1 ; si ++) { for (; sj \u0026lt; LENGTH * j + LENGTH - 1 ; sj ++) { if(get(si,sj)[0] != 0){ count += 1; } } } let shade = (count/total)*10; board._memory2D[j][i]=[red(0), green(255*shade), blue(0), alpha(255)]; } } } Resultados # Pre AA\nPost AA\nConclusiones # El algoritmo es capaz de ser paralelizable para un mejor rendimiento. Dada la base tan robusta y sencilla del SS este ha derivado en otros m√©todos como el DLSS. La informaci√≥n inicial deberia ser capaz de obtenerse sin bordes para dibujarlos con AA (QuadrilleJS en los bordes \u0026ldquo;√Ønferiores\u0026rdquo;). Junto con el calculo de bordes daria un muy buen resultado con el algoritmo de Edge AA. Entre mucho mayor sea la resolucion del super sampling, se obtienen profundidades de colores intermedias mas precisas, pero llega un punto en que no se notara la diferencia. Referencias # Algoritmos de antialiasing - Gabriel Ma√±ana Guich√≥n Nvidia DLSS AMD FidelityFx CAS Mas algoritmos de Antialiasing QuadrilleJS\n"},{"id":3,"href":"/showcasevc/docs/shortcodes/Interactions-3D/","title":"Interactions 3 D","section":"Shortcodes","content":" Investigaci√≥n sobre interacci√≥nes de usuario en 3D # (A Survey of Interaction Techniques for Interactive 3D Environments) - Jacek Jankowski, Martin Hachet\nAcademic report # Introducci√≥n: # Teniendo en cuenta la tematica adelantada en clase, y su amplio espectro, decidimos enfocarnos en las interacciones de usuario en 3D. Mas especificamente las interacciones hombre maquina dentro de un espacio virtual simulado en la computadora. Y es que a pesar de que todos hemos crecido y vivido en un entorno 3D y por tanto hemos desarrollado habilidades para interactuar en el mismo, a menudo nos resulta dif√≠cil interacturar en entronos 3D interactivos, y segun Jankowski[1] frecuentemente esto es resultado de una interfaz de usuario mal dise√±ada o debido a una selecci√≥n inadecuada de t√©cnicas de interacci√≥n.\nLiteratura: # Entornos 3D: # Se definen los entornos 3D interactivos como representaciones inform√°ticas del mundo real o espacios imaginarios a trav√©s de los cuales los usuarios pueden navegar y en los que pueden interacturar con objetos en tiempo real. A diferencia de los entornos virtuales inmersivos , que utilizan pantallas especializadas y dispositivos de interacci√≥n, como pantallas montadas en la cabeza, para crear una sensaci√≥n de presencia para los usuarios dentro del mundo virtual, los entornos 3D interactivos no se limitan al contexto inmersivo y aprovechan los recursos comunes y general de hardware, es decir mouse y teclado como multi_touch input.\nTendremos en cuenta la clasificaci√≥n de las interacciones en un ambiente interactivo 3D que encontramos en el libro de Jankowski[1] que habla de 3 tareas de interaccion universales: Navegaci√≥n, Selecci√≥n y manipulaci√≥n, y Control de sistema.\nNavegaci√≥n: # Se refiere a la tarea motora de mover el punto de vista del usuario a trav√©s de un entorno; incluye un componente cognitivo: orientaci√≥n.\nLos entornos 3D interactivos suelen representar m√°s espacio del que se puede ver desde un solo punto. Los usuarios deben poder moverse dentro del entorno para obtener diferentes vistas de la escena. Este proceso de desplazarse por un entorno virtual mientras se realiza un seguimiento del propio paradero y los objetivos de la tarea es el tema de una serie de t√©cnicas a las que a menudo se hace referencia con nombres como orientaci√≥n, locomoci√≥n, navegaci√≥n y c√°mara.\nHay que resaltar que es dif√≠cil desarrollar una t√©cnica eficaz para la navegaci√≥n en entornos 3D interactivos. En primer lugar, el control del punto de vista implica seis grados de libertad : tres dimensiones para la ubicaci√≥n posicional (traslaci√≥n) y tres para la ubicaci√≥n angular (rotaci√≥n).\nSegun algunas literaturas podemos agrupoar 4 tipos de movimiento de punto de vista para espacios de trabajo 3D interactivos:\nMovimiento general: Movimiento exploratorio, como caminar a trav√©s de una simulaci√≥n de un dise√±o arquitect√≥nico\nMovimiento dirigido: Movimiento con respecto a un objetivo espec√≠fico, como moverse para examinar un detalle de un modelo de ingenier√≠a.\nMovimiento de coordenadas especificado: Movimiento a una posici√≥n y orientaci√≥n precisas, como una posici√≥n de visualizaci√≥n espec√≠fica en relaci√≥n con un modelo CAD: el usuario debe proporcionar la posici√≥n y orientaci√≥n exactas de su destino.\nMovimiento de trayectoria especificado: Movimiento a lo largo de una trayectoria de posici√≥n y orientaci√≥n, como el movimiento de una c√°mara cinematogr√°fica (corresponde al objetivo Maniobra de Bowman et al. y al objetivo Inspecci√≥n de Tan et al.).\nSelecci√≥n y manipulaci√≥n: # Otra tarea t√≠pica que se realiza en un entorno virtual 3D es la selecci√≥n de objetos y su manipulaci√≥n directa mediante la especificaci√≥n su posici√≥n, orientaci√≥n y escala. Encontramos que las t√©cnicas de interacci√≥n mas comunes en la literatura para la manipulaci√≥n 3D incluyen tres tareas fundamentales: traducci√≥n de objetos (posicionamiento), rotaci√≥n de objetos y escalado de objetos. Las t√©cnicas de interacci√≥n para la manipulaci√≥n 3D incluyen tres tareas fundamentales: traducci√≥n de objetos (posicionamiento), rotaci√≥n de objetos y escalado de objetos.\nSeleccion de objetos: # La forma m√°s com√∫n de seleccionar objetos en los VE de escritorio es colocar el cursor del mouse sobre un objeto dado y hacer clic en un bot√≥n del mouse. La t√©cnica se basa en la proyecci√≥n de rayos (ray casting); utiliza el rayo desde el punto del ojo a trav√©s del p√≠xel actualmente seleccionado por el puntero del mouse para encontrar el primer punto de intersecci√≥n con la escena (la superficie del objetivo o su superficie aproximada, por ejemplo, el cuadro delimitador). Si el rayo virtual se cruza con un objeto, se puede seleccionar para una mayor manipulaci√≥n.\nManipulaci√≥n de objeto: # La manipulaci√≥n de objetos es otra tarea b√°sica que se realiza en un entorno virtual 3D, especialmente durante la construcci√≥n de escenas. Al dise√±ar una escena con m√∫ltiples objetos, los usuarios tienen que realinear y ajustar varias partes repetidamente. Es importante proporcionar una t√©cnica de manipulaci√≥n de objetos eficiente.\nControl del sistema: # Se refiere a la comunicaci√≥n entre el usuario y el sistema que no forma parte del entorno virtual.\nSe puede enfocar en una tarea en la que se aplica un comando para cambiar el estado del sistema o el modo de interacci√≥n .Se se√±ala que aunque el movimiento del punto de vista y la selecci√≥n/manipulaci√≥n se han estudiado ampliamente, se ha investigado muy poco sobre las tareas de control del sistema. Sin embargo, las t√©cnicas de control de aplicaciones se han estudiado intensamente durante los √∫ltimos 40 a√±os en las interfaces gr√°ficas de usuario WIMP 2D \u0026ldquo;apuntar y hacer clic\u0026rdquo; (interfaces basadas en ventanas, √≠conos, men√∫s y un dispositivo se√±alador, generalmente un mouse).\n# Metodos # "},{"id":4,"href":"/showcasevc/docs/shortcodes/masking/","title":"Masking","section":"Shortcodes","content":" Masking # En esta tem√°tica se desarroll√≥ un entorno de ejecuci√≥n para visualizar los efectos de algunos kernels en matrices de convolucion sobre imagenes para su posterior uso como base en un algoritmo que calcula los bordes de las mismas im√°genes mediante derivadas parciales en dos variables.\n"},{"id":5,"href":"/showcasevc/docs/shortcodes/masking/maskingLab/","title":"Masking Lab","section":"Masking","content":" Masking Lab # Seccion de pruebas de matrices de convolucion como paso intermedio para el c√°lculo de bordes mediante derivadas parciales.\n"},{"id":6,"href":"/showcasevc/docs/shortcodes/masking/maskingRes/","title":"Masking Res","section":"Masking","content":" Masking Results # Conceptos # Lo primero que se realiz√≥ fue programar la funci√≥n que permitir√° la convoluci√≥n de un kernel sobre una imagen de acuerdo con lo encontrado en wikipedia\nExpand ‚Üï Wiki pseudocode # for each image row in input image: for each pixel in image row: set accumulator to zero for each kernel row in kernel: for each element in kernel row: if element position corresponding* to pixel position then multiply element value corresponding* to pixel value add result to accumulator endif set output image pixel to accumulator la implementaci√≥n concreta es la siguiente\nExpand ‚Üï p5 code # p.convolute = function (matrix){ img.loadPixels(); let rtotal = 0.0; let gtotal = 0.0; let btotal = 0.0; let postconv = p.createImage(400,400); for (let i = 1; i \u0026lt; 399; i++){ for (let j = 1; j \u0026lt; 399; j++){ rtotal = 0.0; gtotal = 0.0; btotal = 0.0; for (let k = -1; k \u0026lt;= 1; k++){ for (let l = -1; l \u0026lt;= 1; l++){ let xpos = i+k; let ypos = j+l; let red = p.red(img.get(xpos,ypos)); let green = p.green(img.get(xpos,ypos)); let blue = p.blue(img.get(xpos,ypos)); rtotal += red * matrix[k+1][l+1]; gtotal += green * matrix[k+1][l+1]; btotal += blue * matrix[k+1][l+1]; } } rtotal = p.constrain(rtotal, 0, 255); gtotal = p.constrain(gtotal, 0, 255); btotal = p.constrain(btotal, 0, 255); let c = p.color(rtotal,gtotal,btotal); postconv.set(i,j,c); } } postconv.updatePixels(); img = postconv; img.updatePixels(); p.square(0,200,400); p.drawimg(img,0,200); console.log('convolucion realizada! :D'); } Una derivada parcial nos indica como se mueve la pendiente en ese punto para la funcion (imagen)\nhttps://mathinsight.org/partial_derivative_limit_definition\ncodigo de detecci√≥n de bordes:\nExpand ‚Üï p5 code # p.calcborders = function(){ let prebord = p.createImage(400,400); for (let i = 0; i \u0026lt; 400; i++) { for (let j = 0; j \u0026lt; 400; j++) { let g = (p.red(img.get(i,j))+p.green(img.get(i,j))+p.blue(img.get(i,j)))/3; prebord.set(i,j,g); } } let med = [0,0,0,0,0,0,0,0,0]; for (let r = 0; r \u0026lt; 3; r++) { for (let i = 1; i \u0026lt; 400-1; i++) { for (let j = 1; j \u0026lt; 400-1; j++) { med[0] = prebord.get(i - 1,j - 1); med[1] = prebord.get(i,j - 1); med[2] = prebord.get(i + 1,j - 1); med[3] = prebord.get(i - 1,j); med[4] = prebord.get(i,j); med[5] = prebord.get(i + 1,j); med[6] = prebord.get(i - 1,j + 1); med[7] = prebord.get(i,j + 1); med[8] = prebord.get(i + 1,j + 1); med.sort(); prebord.set(i,j,med[4]); } } } let gradx = p.zeroes([400,400]); let grady = p.zeroes([400,400]); for (let i = 0; i \u0026lt; 400-1; i++) { for (let j = 0; j \u0026lt; 400-1; j++) { gradx[i][j] = p.red(img.get(i+1,j)) - p.red(img.get(i,j)); grady[i][j] = p.red(img.get(i,j+1)) - p.red(img.get(i,j)); } } let gradmag = p.zeroes([400,400]); let gradang = p.zeroes([400,400]); for (let i = 0; i \u0026lt; 400-1; i++) { for (let j = 0; j \u0026lt; 400-1; j++) { gradmag[i][j]= p.abs(p.sqrt((gradx[i][j]*gradx[i][j])+(grady[i][j]*grady[i][j]))); gradang[i][j]= p.atan2(grady[i][j],gradx[i][j]); } } let borders = p.zeroes([400,400]); for (let i = 1; i \u0026lt; 400-1; i++) { for (let j = 1; j \u0026lt; 400-1; j++) { if (gradang[i][j] \u0026gt; 0 \u0026amp;\u0026amp; gradang[i + 1][j] \u0026lt; 0) { borders[i][j] = 1; } else if (gradang[i][j] \u0026lt; 0 \u0026amp;\u0026amp; gradang[i + 1][j] \u0026gt; 0) { borders[i][j] = 1; } else if (gradang[i][j] \u0026gt; 0 \u0026amp;\u0026amp; gradang[i][j + 1] \u0026lt; 0) { borders[i][j] = 1; } else if (gradang[i][j] \u0026lt; 0 \u0026amp;\u0026amp; gradang[i][j + 1] \u0026gt; 0) { borders[i][j] = 1; } } } for (let i = 1; i \u0026lt; 400-1; i++) { for (let j = 1; j \u0026lt; 400-1; j++) { if( borders[i][j-1] == 0 \u0026amp;\u0026amp; borders[i-1][j] == 0 \u0026amp;\u0026amp; borders[i+1][j] == 0 \u0026amp;\u0026amp; borders[i][j+1] == 0 ){ borders[i][j] = 0; } } } let postbord = p.createImage(400,400); for (let i = 0; i \u0026lt; 400; i++) { for (let j = 0; j \u0026lt; 400; j++) { if (borders[i][j] == 1) { //postbord.set(i, j, p.color(0,0,0)); postbord.set(i, j, p.color(255,255,255)); } else { //postbord.set(i, j, p.color(255,255,255)); postbord.set(i, j, p.color(0,0,0)); } } } postbord.updatePixels(); console.log(prebord); console.log(postbord); bord = postbord; p.image(bord, 0, 650,400,400); } Imagenes convolucionadas y bordes # Los siguientes resultados poseen un error en la funcion de convolucion que intercambia el valor de verdes por azules y viceversa, visible en el resultado de la convoluci√≥n, pero esto mismo debido a que es una permutaci√≥n no afecta el calculo de bordes el cual se hace a partir de la imagen en escala de grises.\nimagen base: # identidad / sin mascara : # sharpen : # ridge : # box blur: # composition: # "},{"id":7,"href":"/showcasevc/docs/shortcodes/members/","title":"Members","section":"Shortcodes","content":" Members # Nicholson Stive Ochoa # Estudiante de Ingenieria de Sistemas y Computacion en la Universidad Nacional de Colombia.\nIntereses ü§î # Acad√©micos üìò Desarrollo web Inteligencia artificial Desarrollo en multiplataforma Pasatiempos üéÆüé∏ Ver anime y series Hacer ejercicio Daniel Arturo Moreno # Estudiante de Ingenieria de Sistemas y Computacion en la Universidad Nacional de Colombia.\nIntereses ü§î # Acad√©micos üìò\nDesarrollo Web Arduino Linux Procesamiento de im√°genes Programaci√≥n Competitiva y Algoritmia Pasatiempos üéÆüé∏\nGeoguessr RPGs M√∫sica Johan Sebastian Romero # Estudiante de Ingenieria de Sistemas y Computacion en la Universidad Nacional de Colombia.\nIntereses ü§î # Acad√©micos üìò\nDesarrollo Web Procesamiento de imagenes Arquitectura de software Pasatiempos üéÆüé∏\nVideojuegos (Wow) Motociclismo off road Anime "},{"id":8,"href":"/showcasevc/docs/shortcodes/shaders/","title":"Shaders","section":"Shortcodes","content":" Shaders # Introducci√≥n: # Como etapa final de la materia dimos un vistazo al tema de shaders y su aplicaci√≥n en distintos ejemplos expuestos por el profesor, como lo son Coloring, Texturing, Image Processing, y Procedural Texturing. Por esta raz√≥n, para esta entrega final profundizamos en cada uno de estos temas e hicimos nuestras propias modificaciones y propias implementaciones para entender y mostrar que nuevas cosas se pueden hacer con shaders. shaders Adicionalmente aplicamos estos conocimientos adquiridos a una entrega anterior en la que se aplicaron tecnicas de antialising, obteniendo unos resultados interesantes.\nRevisi√≥n de literatura/Antecedentes: # Shader (Sombreador): # Es un programa que ejecuta o realiza c√°lculos matematicos para manipular los atributos de una o varias primitivas gr√°ficas. Es una tencnolog√≠a que ha experimentado una r√°pida evoluci√≥n destinada a proporcionar al programador una interacci√≥n con la unidad de procesamiento gr√°fico (GPU) hasta ahora imposible. Los sombreadores son utilizados para realizar transformaciones de v√©rtices o coloreado de p√≠xeles, entre otras labores, con el prop√≥sito de crear efectos especiales, como iluminaci√≥n, fuego o niebla.\nLas unidades que ejecutan los programas shaders est√°n en todas las GPU y a d√≠a de hoy hay decenas de estas en cada GPU, incluyendo las de gama baja. Desde el momento en que para un procesador un p√≠xel, un tri√°ngulo, un v√©rtice o el mapa de una prote√≠na no son m√°s que datos, las unidades que se utilizan para ejecutar estos programas son iguales independientemente del tipo de shader.\nVertex Shader: # En espa√±ol Sombreador de v√©rtices, es una herramienta capaz de trabajar con la estructura de v√©rtices de figuras modeladas en 3D, y realizar operaciones matem√°ticas sobre ella para definir colores, texturas e incidencia de la luz.\nFragment Shader: # Los Fragment Shaders son aquellos que procesan un fragmento (por ejemplo, un p√≠xel) generado por la Rasterizaci√≥n como un conjunto de colores y un valor de profundidad. Por lo tanto, estos son conjuntos de instrucciones que deben actuar al mismo tiempo por cada uno de los p√≠xeles de la pantalla y se comportan diferente dependiendo de su posici√≥n en la pantalla.\nUna diferencia principal es que un sombreador de v√©rtices puede manipular los atributos de los v√©rtices los cu√°les son los puntos de las esquinas de tus pol√≠gonos.\nEl sombreador de fragmentos, por otro lado, se encarga de c√≥mo se ven los p√≠xeles entre los v√©rtices. Se interpolan entre los v√©rtices definidos siguiendo reglas espec√≠ficas.\nReferencias üìö # [1] The Book of Shaders. Vivo, Patricio \u0026amp; Lowe, Jen\n[2] Shader Basics, Blending \u0026amp; Textures ‚Ä¢ Shaders for Game Devs (Part 1). Holm√©r Freya\n[3] Fragment Shader. OpenGL Wiki\n[4] Hard Zone\n[5] Vertex Shader\n"},{"id":9,"href":"/showcasevc/docs/shortcodes/shaders/EdgeAntiAliasing/","title":"Edge Anti Aliasing","section":"Shaders","content":" Edge Anti Aliasing # Seccion de pruebas de el algoritmo propuesto para realizar Edge AA con shaders. Esta secci√≥n es una continuaci√≥n de anteriores entregas en las cuales ya habiamos tratado el tema de mascaras de convoluci√≥n mediante software y sus efectos en la detecci√≥n de bordes ademas de nuestra entrega acerca de los algoritmos de Super Sampling.\nPruebas del Algoritmo # Controles üïπÔ∏è # Haz click y presiona una de las siguientes teclas:\n‚¨ÖÔ∏è Aplicar M√°scara de Ridge ‚û°Ô∏è Edge Anti Aliasing Implementaci√≥n # Para logar implementar lo que haria el algoritmo de Edge AA hicimos uso de dos conjuntos de shaders distintos, uno para poder utilizar la mascara de convolucion correspondiente a Ridge para guardar en un archivo que despues usariamos como insumo para nuestro shader custom basado en mascaras que realiza el suavizado de las texturas mediante promedios de colores en un area de 3x3 circundante al borde solo en los lugares donde el color de la mascara de ridge es muy marcada ( con un valor de 0.2 en todas las componentes de color).\nedgeaa.js # Expand ‚Üï let baseimg; let edgemask; let antialias; let edgeimg; let edged = false; function preload(){ edgemask = readShader(\u0026quot;/showcasevc/p5files/edgeaa/edgemask.frag\u0026quot;,{varyings: Tree.texcoords}); antialias = readShader(\u0026quot;/showcasevc/p5files/edgeaa/antialias.frag\u0026quot;,{varyings: Tree.texcoords}); baseimg = loadImage('/showcasevc/sketches/mayonesito.jpg'); edgeimg = loadImage('/showcasevc/sketches/bordesmayonesito.png'); } function setup() { createCanvas(500, 500, WEBGL); noStroke(); noLoop(); textureMode(NORMAL); loadPixels(); } function draw() { background(0); image(baseimg,-250,-250); } function keyPressed () { if(keyCode === RIGHT_ARROW){ applyAA(); } if(keyCode === LEFT_ARROW){ applyMask(); } if(keyCode === UP_ARROW){ resetImg(); } } function resetImg(){ edged = false; edgemask.setUniform('dosom',false); quad(-250,-250,250,-250,250,250,-250,250); } function applyAA(){ if(edged){ shader(antialias); antialias.setUniform('textureimg',baseimg); antialias.setUniform('textureedge',edgeimg); antialias.setUniform('texOffset',[1/500,1/500]); quad(-250,-250,250,-250,250,250,-250,250); } } function applyMask(){ background(0); shader(edgemask); edgemask.setUniform('dosom',true); edgemask.setUniform('texture',baseimg); edgemask.setUniform('texOffset',[1/500,1/500]); edgemask.setUniform('mask',[-1,-1,-1,-1,8,-1,-1,-1,-1]); quad(-250,-250,250,-250,250,250,-250,250); edged = true; } edgemask.frag # Expand ‚Üï precision mediump float; uniform sampler2D texture; uniform vec2 texOffset; // holds the 3x3 kernel uniform float mask[9]; uniform bool dosom; varying vec2 texcoords2; void main() { // 1. Use offset to move along texture space. // In this case to find the texcoords of the texel neighbours. vec2 tc0 = texcoords2 + vec2(-texOffset.s, -texOffset.t); vec2 tc1 = texcoords2 + vec2( 0.0, -texOffset.t); vec2 tc2 = texcoords2 + vec2(+texOffset.s, -texOffset.t); vec2 tc3 = texcoords2 + vec2(-texOffset.s, 0.0); // origin (current fragment texcoords) vec2 tc4 = texcoords2 + vec2( 0.0, 0.0); vec2 tc5 = texcoords2 + vec2(+texOffset.s, 0.0); vec2 tc6 = texcoords2 + vec2(-texOffset.s, +texOffset.t); vec2 tc7 = texcoords2 + vec2( 0.0, +texOffset.t); vec2 tc8 = texcoords2 + vec2(+texOffset.s, +texOffset.t); // 2. Sample texel neighbours within the rgba array vec4 rgba[9]; rgba[0] = texture2D(texture, tc0); rgba[1] = texture2D(texture, tc1); rgba[2] = texture2D(texture, tc2); rgba[3] = texture2D(texture, tc3); rgba[4] = texture2D(texture, tc4); rgba[5] = texture2D(texture, tc5); rgba[6] = texture2D(texture, tc6); rgba[7] = texture2D(texture, tc7); rgba[8] = texture2D(texture, tc8); // 3. Apply convolution kernel vec4 convolution; for (int i = 0; i \u0026lt; 9; i++) { convolution += rgba[i]*mask[i]; } // 4. Set color from convolution gl_FragColor = dosom ? vec4(convolution.rgb, 1.0) : rgba[4]; } antialias.frag # Expand ‚Üï precision mediump float; uniform sampler2D textureimg; uniform sampler2D textureedge; uniform vec2 texOffset; // we need our interpolated tex coord varying vec2 texcoords2; void main() { vec4 edgepoint = texture2D(textureedge, texcoords2 + vec2(0.0)); vec2 tc0 = texcoords2 + vec2(-texOffset.s, -texOffset.t); vec2 tc1 = texcoords2 + vec2( 0.0, -texOffset.t); vec2 tc2 = texcoords2 + vec2(+texOffset.s, -texOffset.t); vec2 tc3 = texcoords2 + vec2(-texOffset.s, 0.0); vec2 tc4 = texcoords2 + vec2( 0.0, 0.0); vec2 tc5 = texcoords2 + vec2(+texOffset.s, 0.0); vec2 tc6 = texcoords2 + vec2(-texOffset.s, +texOffset.t); vec2 tc7 = texcoords2 + vec2( 0.0, +texOffset.t); vec2 tc8 = texcoords2 + vec2(+texOffset.s, +texOffset.t); vec4 rgba[9]; rgba[0] = texture2D(textureimg, tc0); rgba[1] = texture2D(textureimg, tc1); rgba[2] = texture2D(textureimg, tc2); rgba[3] = texture2D(textureimg, tc3); rgba[4] = texture2D(textureimg, tc4); rgba[5] = texture2D(textureimg, tc5); rgba[6] = texture2D(textureimg, tc6); rgba[7] = texture2D(textureimg, tc7); rgba[8] = texture2D(textureimg, tc8); vec4 sum = vec4(0.0); for (int i = 0; i \u0026lt; 9; i++) { sum += rgba[i]; } if( (edgepoint.r \u0026gt; 0.2 ) \u0026amp;\u0026amp; (edgepoint.g \u0026gt; 0.2 ) \u0026amp;\u0026amp; (edgepoint.b \u0026gt; 0.2 )){ gl_FragColor = sum*vec4(1.0/9.0); }else{ gl_FragColor = texture2D(textureimg, texcoords2 + vec2(0.0,0.0)); } } Resultados # Como podemos ver en la anterior imagen los colores presentes bajo el ojo pero sobre el pico del pato de la imagen estan intactos, donde no se presentaban bordes. Pero en una zona mas rica en bordes como lo es a la izquierda del ojo y en el ojo mismo nuestro algoritmo realizo el trabajo de suavizado perfectamente para evitar los escalones en cada pixel y tener una imagen menos agreste en los bordes.\nConclusiones # El algoritmo de EdgeAA nos permite mas que una mejor aplicacion del algoritmo de Super Sampling, una versi√≥n mas eficiente de esta misma. Esto debido a que la variaci√≥n que realiza respecto a otros m√©todos es la no aplicaci√≥n de forma general a la imagen sino en √°reas especificas y con un √©nfasis que se puede acomodar por el usuario o parametrizador el valor de corte de 0.2 en las componentes de color de la imagen de bordes nos permitio una aplicacion aceptable en la imagen sin llegar a los artefactos que se llegan a presentar si realizaramos un corte en 0.5 o en 0.1 por el sobreuso o el poco uso del suavizado. "},{"id":10,"href":"/showcasevc/docs/shortcodes/shaders/imageProcessing/","title":"Image Processing","section":"Shaders","content":" Image Processing # En esta secci√≥n tambien vamos a tener como referencia nuestra primera entrega en la secci√≥n de masking para afianzar los conceptos y comparar el rendimiento.\nDesarrollo de los Ejercicios # Controles # Haz click y presiona una de las siguientes teclas:\n‚¨ÖÔ∏è Resetear ‚û°Ô∏è Aplicar M√°scara de Ridge Imagen # Video # (puede tardar en cargar unos segundos) Implementaci√≥n # Imagen # Expand ‚Üï let baseimg; let rstimg; let maskShader; function preload(){ maskShader = readShader(\u0026quot;/showcasevc/p5files/shadersJohan/mask.frag\u0026quot;,{varyings: Tree.texcoords}); baseimg = loadImage('/showcasevc/sketches/mayonesito.jpg'); rstimg = baseimg; } function setup() { createCanvas(500, 500, WEBGL); noStroke(); noLoop(); textureMode(NORMAL); loadPixels(); } function draw() { background(0); image(rstimg,-250,-250); shader(maskShader); maskShader.setUniform('texture',baseimg); maskShader.setUniform('texOffset',[1/500,1/500]); maskShader.setUniform('mask',[-1,-1,-1,-1,8,-1,-1,-1,-1]); maskShader.setUniform('dosom',false); } function keyPressed () { if(keyCode === RIGHT_ARROW){ applyMask(); } if(keyCode === LEFT_ARROW){ resetMask(); } } function resetMask(){ maskShader.setUniform('dosom',false); quad(-250,-250,250,-250,250,250,-250,250); } function applyMask(){ maskShader.setUniform('dosom',true); quad(-250,-250,250,-250,250,250,-250,250); } Video # Expand ‚Üï let basevid; let maskShader; let isVidReady = false; let dosom = false; function onVideoLoad(){ isVidReady = true; } function preload(){ maskShader = readShader(\u0026quot;/showcasevc/p5files/shadersJohan/mask.frag\u0026quot;,{varyings: Tree.texcoords}); basevid = createVideo('/showcasevc/sketches/fingers.webm',onVideoLoad()); basevid.hide(); } function setup() { createCanvas(300, 300, WEBGL); basevid.size(300,300); noStroke(); } function draw() { background(0); if(isVidReady){ quad(-150,-150,150,-150,150,150,-150,150); } basevid.loop(); shader(maskShader); maskShader.setUniform('texture',basevid); maskShader.setUniform('texOffset',[1/300,1/300]); maskShader.setUniform('mask',[-1,-1,-1,-1,8,-1,-1,-1,-1]); maskShader.setUniform('dosom',dosom); } function keyPressed () { if(keyCode === RIGHT_ARROW){ applyMask(); } if(keyCode === LEFT_ARROW){ resetMask(); } } function resetMask(){ dosom = false; maskShader.setUniform('dosom',dosom); if(isVidReady){ quad(-150,-150,150,-150,150,150,-150,150); } } function applyMask(){ dosom = true; maskShader.setUniform('dosom',dosom); if(isVidReady){ quad(-150,-150,150,-150,150,150,-150,150); } } mask.frag # Expand ‚Üï precision mediump float; uniform sampler2D texture; uniform vec2 texOffset; // holds the 3x3 kernel uniform float mask[9]; uniform bool dosom; // we need our interpolated tex coord varying vec2 texcoords2; void main() { // 1. Use offset to move along texture space. // In this case to find the texcoords of the texel neighbours. vec2 tc0 = texcoords2 + vec2(-texOffset.s, -texOffset.t); vec2 tc1 = texcoords2 + vec2( 0.0, -texOffset.t); vec2 tc2 = texcoords2 + vec2(+texOffset.s, -texOffset.t); vec2 tc3 = texcoords2 + vec2(-texOffset.s, 0.0); // origin (current fragment texcoords) vec2 tc4 = texcoords2 + vec2( 0.0, 0.0); vec2 tc5 = texcoords2 + vec2(+texOffset.s, 0.0); vec2 tc6 = texcoords2 + vec2(-texOffset.s, +texOffset.t); vec2 tc7 = texcoords2 + vec2( 0.0, +texOffset.t); vec2 tc8 = texcoords2 + vec2(+texOffset.s, +texOffset.t); // 2. Sample texel neighbours within the rgba array vec4 rgba[9]; rgba[0] = texture2D(texture, tc0); rgba[1] = texture2D(texture, tc1); rgba[2] = texture2D(texture, tc2); rgba[3] = texture2D(texture, tc3); rgba[4] = texture2D(texture, tc4); rgba[5] = texture2D(texture, tc5); rgba[6] = texture2D(texture, tc6); rgba[7] = texture2D(texture, tc7); rgba[8] = texture2D(texture, tc8); // 3. Apply convolution kernel vec4 convolution; for (int i = 0; i \u0026lt; 9; i++) { convolution += rgba[i]*mask[i]; } // 4. Set color from convolution gl_FragColor = dosom ? vec4(convolution.rgb, 1.0) : rgba[4]; } Conclusiones # La aplicacion de m√°scaras mediante el uso de shaders es notablemente m√°s rapido gracias al uso de la tarjeta gr√°fica del computador. Esto se puede hacer tangible no solo en la velocidad del proceso, sino que tambien en el hecho de que podemos implementar el mismo shader para imagenes en video y poder realizar el proceso en tiempo real en lugar de tener que esperar aproximadamente 20 segundos +/- 1, a poder realizarlo varias veces por segundo. La cantidad de c√≥digo escrito por nosotros es menor y mas eficiente gracias a las librerias y los shaders que se usaron. "},{"id":11,"href":"/showcasevc/docs/shortcodes/shaders/Procedural/","title":"Procedural","section":"Shaders","content":" Procedural Texturing # En esta secci√≥n aplicamos el ejemplo visto en clase desde el cual se generaba una textura proceduralmente aplicando el patr√≥n truchet tiles, pero en este caso, sobre un objeto distinto.\nDesarrollo del Ejercicio # Implementaci√≥n # sketch.js # Expand ‚Üï let pg; let truchetShader; let frames=0; let frames2=100; function preload() { // shader adapted from here: https://thebookofshaders.com/09/ truchetShader = readShader('/showcasevc/p5files/nicholsonSketch/procedural/truchet.frag', { matrices: Tree.NONE, varyings: Tree.NONE }); } function setup() { createCanvas(400, 400, WEBGL); // create frame buffer object to render the procedural texture pg = createGraphics(400, 400, WEBGL); textureMode(NORMAL); noStroke(); pg.noStroke(); pg.textureMode(NORMAL); // use truchetShader to render onto pg pg.shader(truchetShader); // emitResolution, see: // https://github.com/VisualComputing/p5.treegl#macros pg.emitResolution(truchetShader); // https://p5js.org/reference/#/p5.Shader/setUniform truchetShader.setUniform('u_zoom', 3); // pg clip-space quad (i.e., both x and y vertex coordinates ‚àà [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); // set pg as texture texture(pg); } function draw() { background(33); orbitControl(); rotateZ(frames * 0.005); rotateX(frames * 0.005); rotateY(frames * 0.005); truchetShader.setUniform('u_zoom', int(map(frames2*0.1, 0, width, 1, 30))); pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); frames++; frames2 = frames2 + 2; sphere(100,200); } function mouseMoved() { // https://p5js.org/reference/#/p5.Shader/setUniform truchetShader.setUniform('u_zoom', int(map(mouseX, 0, width, 1, 30))); // pg clip-space quad (i.e., both x and y vertex coordinates ‚àà [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); } "},{"id":12,"href":"/showcasevc/docs/shortcodes/shaders/texturing/","title":"Texturing","section":"Shaders","content":" Texturing # En esta secci√≥n implementamos otros m√©todos propuestos para la visualizaci√≥n de la luz o el brillo, haciendo uso del value de HSV y lightness de HSL.\nDesarrollo de los Ejercicios # Controles üïπÔ∏è # Haz click y presiona una de las siguientes teclas:\n‚¨ÖÔ∏è Resetear ‚¨áÔ∏è HSL ( L ) ‚¨ÜÔ∏è HSV ( V ) ‚û°Ô∏è Promedio Implementaci√≥n # Promedio RGB # Expand ‚Üï if(avg){ return 0.3333 * texel.r + 0.3333 * texel.g + 0.3333 * texel.b + 0.1; } HSV V # Teniendo en cuenta que el value del HSV corresponde al m√°ximo entre los valores del RGB, entonces\nExpand ‚Üï if(val){ if ( texel.r \u0026gt; texel.g \u0026amp;\u0026amp; texel.r \u0026gt; texel.b){ return texel.r * 1.0 + 0.1; } else if (texel.g \u0026gt; texel.r \u0026amp;\u0026amp; texel.g \u0026gt; texel.b){ return texel.g * 1.0 + 0.1; } else if (texel.b \u0026gt; texel.r \u0026amp;\u0026amp; texel.b \u0026gt; texel.g) { return texel.b * 1.0 + 0.1; } } HSL L # A partir de los valores RGB se puede obtener el lightness a partir de el valor medio de estos, es decir: Expand ‚Üï if(lum){ float max = 0.0; float min = 0.0; if ( texel.r \u0026gt; texel.g \u0026amp;\u0026amp; texel.r \u0026gt; texel.b){ max = texel.r; } else if (texel.g \u0026gt; texel.r \u0026amp;\u0026amp; texel.g \u0026gt; texel.b){ max = texel.g; } else if (texel.b \u0026gt; texel.r \u0026amp;\u0026amp; texel.b \u0026gt; texel.g) { max = texel.b; } if ( texel.r \u0026lt; texel.g \u0026amp;\u0026amp; texel.r \u0026lt; texel.b){ min = texel.r; } else if (texel.g \u0026lt; texel.r \u0026amp;\u0026amp; texel.g \u0026lt; texel.b){ min = texel.g; } else if (texel.b \u0026lt; texel.r \u0026amp;\u0026amp; texel.b \u0026lt; texel.g) { min = texel.b; } return max * 0.5 + min * 0.5 + 0.1; } "},{"id":13,"href":"/showcasevc/docs/shortcodes/terrain/","title":"Terrain","section":"Shortcodes","content":" Creating a terrain with p5.js # Academic report # Introducci√≥n: # En el marco de trabajo presentado por el profesor en clase, que enmarcaba varios tipos de ilusiones, nos llam√≥ la atenci√≥n el titulado MACH BANDS , el cual se enfocaba en la generaci√≥n de un terreno con una superficie natural con la aplicaci√≥n del efecto nombrado.\nPara lograr el objetivo utilizamos la libreria p5.js, la cual utilizaremos posiblemente durante los proyectos del semestre por recomendaci√≥n del profesor y no valemos de una libreria integrada de p5 llamada Perlin noise para tratar de generar una textura natural para el terreno.\nLiteratura: # p5.js: # Es una biblioteca de JavaScript para la codificaci√≥n creativa, con un enfoque en la realizaci√≥n de la codificaci√≥n accesible e inclusiva para artistas, dise√±adores, educadores, principiantes y cualquier otra persona. P5.js es gratuito y de c√≥digo abierto porque la filosofia de los creadores es que el software, y las herramientas para aprenderlo, deben ser accesibles para todos.(p5js.org)\nPerlin noise # Es un generador de secuencias aleatorias que produce una sucesi√≥n de n√∫meros arm√≥nicos ordenados de forma m√°s natural en compraci√≥n con la funci√≥n est√°ndar aleatoria (). Fue inventado por Ken Perlin en la d√©cada de 1980 y se ha utilizado desde aplicaciones gr√°ficas para producer textura de procedimiento, movimiento natural, formas, terrenos, etc. (p5js.org)\nLa mayor diferencia con random() es que perlin noise se define en un espacio N-dimensional infinito donde cada par de coordenadas corresponde a un valor semi-aleatorio fijo.\nMetodos # Terrain1 Terrain # En el primer terreno creado usamos TRIANGLE_STRIP como parametro para la funci√≥n beginShape() Terrain2 Terrain # En esta iteraci√≥n se hace uso del efecto de la banda de Mach para representar una ilusion de gradiente en la visualizaci√≥n del terreno. Terrain3 Terrain # Por ultimo utilizamos el parametro TRIANGLE_FAN. Terrain Res #Terrain Con TRIANGLE_STRIP la figura a manejar es mas grande y por ende se utilizan menos recursos. Pero el relleno es mas complicado. Con la ilusion generada por la banda de Mach encontramos un rendimiento aceptable. El efecto de relleno visual es natural exceptuando nuestro enfasis al marcar los bordes. Con TRIANGLE_FAN la figura a manejar es mas peque√±a y por ende se utilizan mas recursos. Pero el relleno es mas detallado y natural. "},{"id":14,"href":"/showcasevc/docs/shortcodes/terrain/terrain1/","title":"Terrain1","section":"Terrain","content":" Terrain # En el primer terreno creado usamos TRIANGLE_STRIP como parametro para la funci√≥n beginShape()\n"},{"id":15,"href":"/showcasevc/docs/shortcodes/terrain/terrain2/","title":"Terrain2","section":"Terrain","content":" Terrain # En esta iteraci√≥n se hace uso del efecto de la banda de Mach para representar una ilusion de gradiente en la visualizaci√≥n del terreno.\n"},{"id":16,"href":"/showcasevc/docs/shortcodes/terrain/terrain3/","title":"Terrain3","section":"Terrain","content":" Terrain # Por ultimo utilizamos el parametro TRIANGLE_FAN.\n"},{"id":17,"href":"/showcasevc/docs/shortcodes/terrain/terrainRes/","title":"Terrain Res","section":"Terrain","content":"#Terrain\nCon TRIANGLE_STRIP la figura a manejar es mas grande y por ende se utilizan menos recursos.\nPero el relleno es mas complicado.\nCon la ilusion generada por la banda de Mach encontramos un rendimiento aceptable.\nEl efecto de relleno visual es natural exceptuando nuestro enfasis al marcar los bordes.\nCon TRIANGLE_FAN la figura a manejar es mas peque√±a y por ende se utilizan mas recursos.\nPero el relleno es mas detallado y natural.\n"},{"id":18,"href":"/showcasevc/docs/shortcodes/Transformations/","title":"Transformations","section":"Shortcodes","content":" Creating a Matrix Transformation based cube with p5.js # Academic report # Introducci√≥n: # Durante el desarrollo del workshop, buscamos una manera did√°ctica de llevar a cabo una representaci√≥n gr√°fica de la implementaci√≥n de transformaciones matriciales, y finalmente se plante√≥ que un Cubo de Rubik puede involucrar varios de estos conceptos, especialmente si se habla de Transformaciones Lineales.\nLiteratura: # Transformaciones Lineales # Como se puede imaginar, hay una cantidad inimaginablemente enorme de transformaciones posibles, la mayor√≠a de las cuales ser√≠a bastante complicado pensar en ellas. Afortunadamente, el √°lgebra lineal suele estar limitada a un tipo especial de transformaci√≥n que es m√°s f√°cil de entender: las transformaciones lineales.\nVisualmente, esto significa que toda la cuadr√≠cula de puntos 2d \u0026ldquo;sigue\u0026rdquo; con √Æ y ƒµ, por as√≠ decirlo. Puedes saber que una transformaci√≥n es lineal si todas esas l√≠neas de cuadr√≠cula que comenzaron paralelas y espaciadas uniformemente permanecen paralelas y espaciadas uniformemente (¬øpor qu√©?). En realidad, es un poco m√°s limitado que eso. Si una transformaci√≥n es lineal, tambi√©n debe fijar el origen en su lugar.\nMatriz de Rotaci√≥n # Rotaci√≥n 2D # Rotaci√≥n 3D # p5.js: # Es una biblioteca de JavaScript para la codificaci√≥n creativa, con un enfoque en la realizaci√≥n de la codificaci√≥n accesible e inclusiva para artistas, dise√±adores, educadores, principiantes y cualquier otra persona. P5.js es gratuito y de c√≥digo abierto porque la filosofia de los creadores es que el software, y las herramientas para aprenderlo, deben ser accesibles para todos.(p5js.org)\nReferencias # 3 blue 1 Brown - Linear Transformations\nMetodos # Rubikcube Rubik\u0026rsquo;s Cube # "},{"id":19,"href":"/showcasevc/docs/shortcodes/Transformations/rubikcube/","title":"Rubikcube","section":"Transformations","content":" Rubik\u0026rsquo;s Cube # "}]